{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "feel_classifications_pytorch_kobert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f9aa323e7e8d4587b878f0390ed04377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_604f127387a7439ea23cbf24d786823c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5590f6f45846465ebfa2be576e64145d",
              "IPY_MODEL_a4e0d9f35e604721abd633e27efbe793"
            ]
          }
        },
        "604f127387a7439ea23cbf24d786823c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5590f6f45846465ebfa2be576e64145d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7da38f641a0c4f54a9c425bc050d6a32",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 14,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 14,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c7c5f6ba3e424835afb2fc95c964ff6f"
          }
        },
        "a4e0d9f35e604721abd633e27efbe793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab1b2bea75ab45dbabb4c1f180ff73e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 14/14 [04:45&lt;00:00, 20.42s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25d65c343aae4859b714cf07f6dde60a"
          }
        },
        "7da38f641a0c4f54a9c425bc050d6a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c7c5f6ba3e424835afb2fc95c964ff6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab1b2bea75ab45dbabb4c1f180ff73e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25d65c343aae4859b714cf07f6dde60a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLgPYeT1Itsk",
        "outputId": "bca92cec-d703-4b5e-89b3-e2cf7d599a8b"
      },
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n",
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.23)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.45)\n",
            "Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.96)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2a9C65XItso",
        "outputId": "a2bd3b74-c7b4-4f92-b072-76534c6567a3"
      },
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-rx1osk3x\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-rx1osk3x\n",
            "Requirement already satisfied (use --upgrade to upgrade): kobert==0.1.2 from git+https://****@github.com/SKTBrain/KoBERT.git@master in /usr/local/lib/python3.7/dist-packages\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12773 sha256=11270087cfc6b4f4d58d935f008c87c3f39000c579ad56c5cae879b3b0970041\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-linmjgwp/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n",
            "Successfully built kobert\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-2Kw334Itso"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vu3sSHQItsr"
      },
      "source": [
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC7cQoMoItss"
      },
      "source": [
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9fUELsakOvv",
        "outputId": "99aa3e0d-07b4-4cfc-afe2-b9de9e43926f"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdqDzN9nItst"
      },
      "source": [
        "##GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XhlbqGrItst",
        "outputId": "f603430f-7819-4c49-b7c6-9091d922af91"
      },
      "source": [
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n",
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "MYc6YSCikiAM",
        "outputId": "13f36583-49b0-4a46-fcc1-3108714a6adb"
      },
      "source": [
        "# 새로운 데이터셋 불러오는 코드\n",
        "import pandas as pd\n",
        "dataset_train1 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/nlp/dataset.csv')\n",
        "dataset_train1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>언니 동생으로 부르는게 맞는 일인가요..??</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>그냥 내 느낌일뿐겠지?</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>아직너무초기라서 그런거죠?</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>유치원버스 사고 낫다던데</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>근데 원래이런거맞나요</td>\n",
              "      <td>공포</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Sentence Emotion\n",
              "0  언니 동생으로 부르는게 맞는 일인가요..??      공포\n",
              "1              그냥 내 느낌일뿐겠지?      공포\n",
              "2            아직너무초기라서 그런거죠?      공포\n",
              "3             유치원버스 사고 낫다던데      공포\n",
              "4               근데 원래이런거맞나요      공포"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "15WEijxbmef5",
        "outputId": "d05b6330-4f84-4d41-c394-581ef8c2f754"
      },
      "source": [
        "# 감정 라벨링\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(dataset_train1['Emotion'])\n",
        "dataset_train1['Emotion'] = encoder.transform(dataset_train1['Emotion'])\n",
        "dataset_train1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>언니 동생으로 부르는게 맞는 일인가요..??</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>그냥 내 느낌일뿐겠지?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>아직너무초기라서 그런거죠?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>유치원버스 사고 낫다던데</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>근데 원래이런거맞나요</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   Sentence  Emotion\n",
              "0  언니 동생으로 부르는게 맞는 일인가요..??        0\n",
              "1              그냥 내 느낌일뿐겠지?        0\n",
              "2            아직너무초기라서 그런거죠?        0\n",
              "3             유치원버스 사고 낫다던데        0\n",
              "4               근데 원래이런거맞나요        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZroqcHrm4cu",
        "outputId": "fe8d0de7-ecbc-4e5f-f2da-025428b73933"
      },
      "source": [
        "# 라벨링된 감정 매핑 {0: '공포', 1: '놀람', 2: '분노', 3: '슬픔', 4: '중립', 5: '행복', 6: '혐오'}\n",
        "mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
        "mapping"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '공포', 1: '놀람', 2: '분노', 3: '슬픔', 4: '중립', 5: '행복', 6: '혐오'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C986OtXZnHLd",
        "outputId": "938a116e-0d67-4584-9b5f-da9567b7167b"
      },
      "source": [
        "# Train / Test set 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(dataset_train1, test_size=0.2, random_state=42)\n",
        "print(\"train shape is:\", len(train))\n",
        "print(\"test shape is:\", len(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape is: 30875\n",
            "test shape is: 7719\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERD6Yqv8Hmis",
        "outputId": "716cb0b1-bc1b-40e0-9788-49cc3e0f2f41"
      },
      "source": [
        "print(train.head())\n",
        "print(test.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                Sentence  Emotion\n",
            "29089                         오오~~바르샤가 좀 더 우승하겠는데~!!ㅋㅋㅋㅋ        5\n",
            "24337  조연도 안되는급인데 이렇게 언플하고도 조연드립치고 쉴드하는 개셈 보면 왜 쓰레기라하...        4\n",
            "20228                 남친 유격훈련가서 연락이 안되여ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ        3\n",
            "18840                               어제전화왔는데 많이힘들어하던데 ...        3\n",
            "10369                             아님 그냥 그대로 남자소유가 되는거임??        1\n",
            "                       Sentence  Emotion\n",
            "34278                   어디서개구라를        6\n",
            "11355           설마 진짜 믿는건 아니겠지?        1\n",
            "26580     끝까지 읽었다고는 말 안했다...ㅎㅎㅎ        4\n",
            "217           교도소에서 골목 대장이 되버렸네        0\n",
            "23737  돈만 주면 맛집되는 참 엉터리 맛집선정...        4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5Cdu4igItsv",
        "outputId": "31dfc242-a615-43aa-cea3-dd812c866a39"
      },
      "source": [
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3vL6HnxItsv"
      },
      "source": [
        "# 테스트데이터셋을 이용한 테스트방식을 위한 데이터변환기\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, bert_tokenizer, max_len, pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i]) for i in dataset['Sentence']]\n",
        "        self.labels = [np.int32(i) for i in dataset['Emotion']]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpqp_bOhd29j"
      },
      "source": [
        "# 실시간 입력 형식을 위한 데이터변환기\n",
        "class BERTDataset2(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1pLEmccItsw"
      },
      "source": [
        "## Setting parameters\n",
        "max_len = 64\n",
        "batch_size = 16\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 10\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4h9_YQSItsw"
      },
      "source": [
        "data_train = BERTDataset(train,  tok, max_len, True, False)\n",
        "data_test = BERTDataset(test, tok, max_len, True, False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A46e-mRaItsw",
        "outputId": "54988a69-2053-4eaa-bd31-bf64306aa905"
      },
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0IvYIwaItsx"
      },
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes=7,\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wpFuDaOItsx"
      },
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBa2OPJyItsx"
      },
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OziryGHRItsy"
      },
      "source": [
        "# AdamW\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "# SGD\n",
        "#optimizer = optim.SGD(optimizer_grouped_parameters, lr=0.01, momentum=0.9)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1n5aAESItsy"
      },
      "source": [
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdaLNfI8Itsy"
      },
      "source": [
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOVgLjfvItsy"
      },
      "source": [
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4c7Ip9rItsz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2ff0a38d-18cd-4f15-b36d-640a74b2c768"
      },
      "source": [
        "# train\n",
        "'''\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/nlp/weights/'\n",
        " \n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train loss {} train acc {}\".format(e+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test loss {} test acc {}\".format(e+1, loss.data.cpu().numpy(), test_acc / (batch_id+1)))\n",
        "'''\n",
        "  \n",
        "'''\n",
        "    # epoch당 한번씩 model을 저장할 때 사용\n",
        "    torch.save({\n",
        "        'epoch' : e+1,\n",
        "        'model_state_dict' : model.state_dict(),\n",
        "        'optimizer_state_dict' : optimizer.state_dict()\n",
        "    }, PATH + 'model_{}.tar'.format(e+1))\n",
        "'''\n",
        "\n",
        "'''\n",
        "# 마지막에 한번만 model을 저장할 때 사용\n",
        "torch.save({\n",
        "    'epoch' : 9,\n",
        "    'model_state_dict' : model.state_dict(),\n",
        "    'optimizer_state_dict' : optimizer.state_dict()\n",
        "}, PATH + 'model_{}_2.tar'.format(e+1))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntorch.save({\\n    'epoch' : 9,\\n    'model_state_dict' : model.state_dict(),\\n    'optimizer_state_dict' : optimizer.state_dict()\\n}, PATH + 'model_{}_2.tar'.format(e+1))\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgTG-EokMHqd"
      },
      "source": [
        "#모델 초기화\n",
        "model1 = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n",
        "\n",
        "#모델 state_dict 불러오기\n",
        "model1.eval()\n",
        "PATH = '/content/drive/MyDrive/Colab Notebooks/nlp/weights/'\n",
        "checkpoint = torch.load(PATH + 'model_10_1.tar')\n",
        "model1.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLgyP6IwcZke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9aa323e7e8d4587b878f0390ed04377",
            "604f127387a7439ea23cbf24d786823c",
            "5590f6f45846465ebfa2be576e64145d",
            "a4e0d9f35e604721abd633e27efbe793",
            "7da38f641a0c4f54a9c425bc050d6a32",
            "c7c5f6ba3e424835afb2fc95c964ff6f",
            "ab1b2bea75ab45dbabb4c1f180ff73e3",
            "25d65c343aae4859b714cf07f6dde60a"
          ]
        },
        "outputId": "a55ff0f1-ddc2-43b2-cfff-e0c841c6af58"
      },
      "source": [
        "# 테스트파일로 테스트하기\n",
        "\n",
        "# 테스트파일 불러오기\n",
        "dataset_test1 = pd.read_csv('/content/drive/My Drive/Colab Notebooks/nlp/test.csv')\n",
        "\n",
        "test_set = BERTDataset(dataset_test1, tok, max_len, True, False)\n",
        "test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=5)\n",
        "\n",
        "newtest_acc = 0.0\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_input)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  label = label.long().to(device)\n",
        "  out = model1(token_ids, valid_length, segment_ids)\n",
        "  newtest_acc += calc_accuracy(out, label)\n",
        "  print(out)\n",
        "  print(out.argmax(), label, \"\\n\")\n",
        "print(\"test acc {}\" .format(newtest_acc /(batch_id+1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9aa323e7e8d4587b878f0390ed04377",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 4.0118, -0.1726, -2.5907,  6.3703, -2.1629, -1.0503, -2.9885]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(3, device='cuda:0') tensor([0], device='cuda:0') \n",
            "\n",
            "tensor([[-1.7977, -1.3352, -1.6244, -1.6279, -1.0812,  8.4428, -0.5522]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(5, device='cuda:0') tensor([5], device='cuda:0') \n",
            "\n",
            "tensor([[ 4.7621,  4.7689, -1.7507, -1.5604, -2.0395, -2.8497, -1.5863]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(1, device='cuda:0') tensor([6], device='cuda:0') \n",
            "\n",
            "tensor([[ 0.7515, -0.2049, -1.2873, -0.5770, -1.8498, -2.3053,  5.6463]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(6, device='cuda:0') tensor([6], device='cuda:0') \n",
            "\n",
            "tensor([[-0.2845, -1.1097, -1.6651,  7.6573, -1.7484, -0.4590, -1.4098]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(3, device='cuda:0') tensor([3], device='cuda:0') \n",
            "\n",
            "tensor([[-1.4167, -1.4797,  6.9720, -0.9932, -0.9105, -2.1389,  0.0767]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(2, device='cuda:0') tensor([2], device='cuda:0') \n",
            "\n",
            "tensor([[ 1.2797,  6.5039, -1.5247, -1.8019,  0.2455, -3.4565, -2.4319]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(1, device='cuda:0') tensor([4], device='cuda:0') \n",
            "\n",
            "tensor([[-1.6018, -1.8211, -1.4984, -1.8127, -0.5033,  8.4268, -0.7270]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(5, device='cuda:0') tensor([5], device='cuda:0') \n",
            "\n",
            "tensor([[-2.8409, -1.6428,  3.2017, -1.9270, -1.7261, -2.1641,  6.9985]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(6, device='cuda:0') tensor([6], device='cuda:0') \n",
            "\n",
            "tensor([[-1.7925, -1.5875,  0.2280, -1.9588, -1.1213, -0.8603,  7.1567]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(6, device='cuda:0') tensor([6], device='cuda:0') \n",
            "\n",
            "tensor([[-3.5382, -2.3027,  6.1941, -1.7925, -1.9211, -0.9250,  4.1826]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(2, device='cuda:0') tensor([6], device='cuda:0') \n",
            "\n",
            "tensor([[-1.4814, -0.8773, -0.1607, -1.2650, -1.1436, -2.1890,  7.0227]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(6, device='cuda:0') tensor([6], device='cuda:0') \n",
            "\n",
            "tensor([[-0.5647,  0.2955, -1.9850, -2.0217, -1.0223,  6.6669, -1.0862]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(5, device='cuda:0') tensor([5], device='cuda:0') \n",
            "\n",
            "tensor([[-1.1645, -0.9532, -0.1321,  7.2129, -1.9186, -0.9684, -1.2761]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor(3, device='cuda:0') tensor([2], device='cuda:0') \n",
            "\n",
            "\n",
            "test acc 0.6428571428571429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0opONe2C15ta"
      },
      "source": [
        "# 해당 인덱스값이 어떤 감정을 나타내는지 바꿔줌.\n",
        "def switch_feel(feel_num):\n",
        "    if feel_num == 0:\n",
        "      return \"공포\"\n",
        "    elif feel_num == 1:\n",
        "      return \"놀람\"\n",
        "    elif feel_num == 2:\n",
        "      return \"분노\"\n",
        "    elif feel_num == 3:\n",
        "      return \"슬픔\"\n",
        "    elif feel_num == 4:\n",
        "      return \"중립\"\n",
        "    elif feel_num == 5:\n",
        "      return \"행복\"\n",
        "    elif feel_num == 6:\n",
        "      return \"혐오\"\n",
        "    return \"무감정\"\n",
        "\n",
        "# 실시간 입력형 테스트방식\n",
        "def predict(predict_sentence):\n",
        "\n",
        "    data = [predict_sentence, '0']\n",
        "    dataset_another = [data]\n",
        "\n",
        "    another_test = BERTDataset2(dataset_another, 0, 1, tok, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test, batch_size=batch_size, num_workers=5)\n",
        "    \n",
        "    model1.eval()\n",
        "\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "\n",
        "        out = model1(token_ids, valid_length, segment_ids)\n",
        "\n",
        "\n",
        "        test_eval=[]\n",
        "        for i in out:\n",
        "            logits=i\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            best = np.argmax(logits)\n",
        "            test_eval.append(best)\n",
        "            #가장 높은것의 값을 -10으로 바꾸어 그 다음으로 높은값을 argmax로 쉽게 찾을 수 있게 함.\n",
        "            logits[best] = -10\n",
        "            test_eval.append(np.argmax(logits))\n",
        "            \n",
        "        # 두번째로 높은 값이 0보다 작을경우에는 입력값의 감정과 연관이 없다고 판단되어 결과출력에서 제외함.    \n",
        "        if logits[test_eval[1]] < 0:\n",
        "            print(\">> 입력내용에서 가장 크게 느껴지는 감정은 \" + switch_feel(test_eval[0]) + \" 입니다.\")\n",
        "        else:\n",
        "            print(\">> 입력내용에서 가장 크게 느껴지는 감정은 \" + switch_feel(test_eval[0]) + \" 이고, 두번째는 \" + switch_feel(test_eval[1]) + \" 입니다.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfN22SPtTpx_",
        "outputId": "0fec25af-20cd-43fd-8503-7aaa532d5215"
      },
      "source": [
        "#입출력 반복 실행. 0 입력시 종료\n",
        "end = 1\n",
        "while end == 1 :\n",
        "    sentence = input(\"입력(0 입력시 종료) : \")\n",
        "    if sentence == \"0\" :\n",
        "        break\n",
        "    predict(sentence)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "입력 : 아파요\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[ 0.28464088 -0.9840919  -1.6508105   7.66206    -1.7783087  -0.77620155\n",
            " -1.7528187 ]\n",
            "[  0.28464088  -0.9840919   -1.6508105  -10.          -1.7783087\n",
            "  -0.77620155  -1.7528187 ]\n",
            ">> 입력내용에서 가장 크게 느껴지는 감정은 슬픔 이고, 두번째는 공포 입니다.\n",
            "\n",
            "\n",
            "입력 : ㅋㅋㅋ개웃겨\n",
            "[-1.730282   -1.4707247  -1.6992302  -1.5970664  -0.8935918   8.438041\n",
            " -0.57226175]\n",
            "[ -1.730282    -1.4707247   -1.6992302   -1.5970664   -0.8935918\n",
            " -10.          -0.57226175]\n",
            ">> 입력내용에서 가장 크게 느껴지는 감정은 행복 입니다.\n",
            "\n",
            "\n",
            "입력 : 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}